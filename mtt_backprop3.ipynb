{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import copy\n",
    "from torchviz import make_dot\n",
    "\n",
    "from src.reparam_module import ReparamModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9998, grad_fn=<DivBackward0>)\n",
      "torch.Size([7, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # No bias because in MTT, we are using normalization layers\n",
    "        self.features = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=3, out_channels=32, kernel_size=3, padding=1, bias=True\n",
    "                ),\n",
    "                nn.GroupNorm(num_groups=32, num_channels=32, affine=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "                nn.Conv2d(\n",
    "                    in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True\n",
    "                ),\n",
    "                nn.GroupNorm(num_groups=32, num_channels=32, affine=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "                nn.Conv2d(\n",
    "                    in_channels=32, out_channels=32, kernel_size=3, padding=1, bias=True\n",
    "                ),\n",
    "                nn.GroupNorm(num_groups=32, num_channels=32, affine=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Linear(32 * 4 * 4 , 9) # Features\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1) # Reshape feature net to [batch_size, H*W/ (2 ** pooling layers)]\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = Model() # Inits with random parameters that are replaced by student_params\n",
    "model_val = copy.deepcopy(model)\n",
    "mtt_model = ReparamModule(model)\n",
    "\n",
    "img_syn = torch.randn(7, 3, 32, 32).requires_grad_(True) # Image input\n",
    "optimizer_img = torch.optim.SGD([img_syn], lr=0.1, momentum=0.5)\n",
    "optimizer_img.zero_grad()\n",
    "\n",
    "mtt_model.train()\n",
    "\n",
    "# Number of learnable parameters\n",
    "param_shapes = [np.prod(p.size()) for p in (mtt_model.parameters())]\n",
    "num_params = sum(param_shapes)\n",
    "# print(num_params)\n",
    "starting_params = torch.randn(num_params)  # Imaginary starting expert param\n",
    "student_params = starting_params.detach().clone().requires_grad_(True) # Student parameters to train, initially starting_params\n",
    "target_params = torch.randn(num_params)  # Imaginary ending expert param\n",
    "\n",
    "out = mtt_model(img_syn, flat_param=student_params) # Forward pass using student_params\n",
    "# print(out.shape)\n",
    "\n",
    "y_hat = torch.empty(out.shape[0], dtype=torch.long).random_(4) # Imaginary targets, shape output of final layer\n",
    "# print(y_hat.shape)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Used to calculate gradients of parameters\n",
    "ce_loss = criterion(out, y_hat)\n",
    "\n",
    "# Computes graph for student_params, but does not populate the .grad attributes!\n",
    "# Returns a tuple with only a single term\n",
    "grad = torch.autograd.grad(ce_loss, student_params, create_graph=True)[0] # CatBackward0\n",
    "grad.retain_grad()\n",
    "\n",
    "# Update student params (instead of using torch.optim.SGD)\n",
    "student_params_new = (student_params - 0.1 * grad) # SubBackward0, MulBackward0, CatBackward0, ViewBackward0,\n",
    "student_params_new.retain_grad() # For validation\n",
    "\n",
    "param_loss = torch.nn.functional.mse_loss(student_params_new, target_params, reduction=\"sum\") # MseLossBackward0\n",
    "param_loss.retain_grad() # For validation\n",
    "param_dist = torch.nn.functional.mse_loss(starting_params, target_params, reduction=\"sum\")\n",
    "\n",
    "# MTT grand loss, with the full computational graph determined by autograd\n",
    "grand_loss = param_loss / param_dist\n",
    "grand_loss.retain_grad() # For validation\n",
    "\n",
    "# Before backwards pass of grand loss, gradient should be zero\n",
    "assert img_syn.grad == None\n",
    "optimizer_img.zero_grad()\n",
    "\n",
    "# Now do backprop, and calculate\n",
    "grand_loss.backward(retain_graph=True) # retain_graph for torchviz\n",
    "\n",
    "# For this case, grand loss should be about 1, because student_params_new = student_params - 0.1 * grad\n",
    "# and we haven't done more update steps, so student_params_new ~ starting_params\n",
    "print(grand_loss)\n",
    "print(img_syn.grad.shape)\n",
    "\n",
    "_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = make_dot(grand_loss, show_attrs=True)\n",
    "# Img may be cut off, hence save to a file\n",
    "graph.render(\"img/conv_grand_loss\", view=True, format=\"pdf\")\n",
    "# graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9937, grad_fn=<DivBackward0>)\n",
      "torch.Size([7, 8])\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(8, 5, bias=False),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(5, 9, bias=True),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(9, 13, bias=True),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.classifier(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = (\n",
    "    Model()\n",
    ")  # Inits with random parameters that are replaced by student_params\n",
    "model_val = copy.deepcopy(model)\n",
    "mtt_model = ReparamModule(model)\n",
    "\n",
    "img_syn = torch.randn(7, 8).requires_grad_(True)  # Image input\n",
    "optimizer_img = torch.optim.SGD([img_syn], lr=0.1, momentum=0.5)\n",
    "optimizer_img.zero_grad()\n",
    "\n",
    "mtt_model.train()\n",
    "\n",
    "# Number of learnable parameters\n",
    "param_shapes = [np.prod(p.size()) for p in (mtt_model.parameters())]\n",
    "num_params = sum(param_shapes)\n",
    "# print(num_params)\n",
    "starting_params = torch.randn(num_params)  # Imaginary starting expert param\n",
    "student_params = (\n",
    "    starting_params.detach().clone().requires_grad_(True)\n",
    ")  # Student parameters to train, initially starting_params\n",
    "target_params = torch.randn(num_params)  # Imaginary ending expert param\n",
    "\n",
    "out = mtt_model(\n",
    "    img_syn, flat_param=student_params\n",
    ")  # Forward pass using student_params\n",
    "# print(out.shape)\n",
    "\n",
    "y_hat = torch.empty(out.shape[0], dtype=torch.long).random_(\n",
    "    4\n",
    ")  # Imaginary targets, shape output of final layer\n",
    "# print(y_hat.shape)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Used to calculate gradients of parameters\n",
    "ce_loss = criterion(out, y_hat)\n",
    "\n",
    "# Computes graph for student_params, but does not populate the .grad attributes!\n",
    "# Returns a tuple with only a single term\n",
    "grad = torch.autograd.grad(ce_loss, student_params, create_graph=True)[\n",
    "    0\n",
    "]  # CatBackward0\n",
    "grad.retain_grad()\n",
    "\n",
    "# Update student params (instead of using torch.optim.SGD)\n",
    "student_params_new =  student_params - 0.1 * grad\n",
    "  # SubBackward0, MulBackward0, CatBackward0, ViewBackward0,\n",
    "student_params_new.retain_grad()  # For validation\n",
    "\n",
    "param_loss = torch.nn.functional.mse_loss(\n",
    "    student_params_new, target_params, reduction=\"sum\"\n",
    ")  # MseLossBackward0\n",
    "param_loss.retain_grad()  # For validation\n",
    "param_dist = torch.nn.functional.mse_loss(\n",
    "    starting_params, target_params, reduction=\"sum\"\n",
    ")\n",
    "\n",
    "# MTT grand loss, with the full computational graph determined by autograd\n",
    "grand_loss = param_loss / param_dist\n",
    "grand_loss.retain_grad()  # For validation\n",
    "\n",
    "# Before backwards pass of grand loss, gradient should be zero\n",
    "assert img_syn.grad == None\n",
    "optimizer_img.zero_grad()\n",
    "\n",
    "# Now do backprop, and calculate\n",
    "grand_loss.backward(retain_graph=True)  # retain_graph for torchviz\n",
    "\n",
    "# For this case, grand loss should be about 1, because student_params_new = student_params - 0.1 * grad\n",
    "# and we haven't done more update steps, so student_params_new ~ starting_params\n",
    "print(grand_loss)\n",
    "print(img_syn.grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img/linear_grand_loss.pdf'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = make_dot(grand_loss, show_attrs=True)\n",
    "# Img may be cut off, hence save to a file\n",
    "graph.render(\"img/linear_grand_loss\", view=True, format=\"pdf\")\n",
    "# graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
