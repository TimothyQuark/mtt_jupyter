{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m num_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(np\u001b[38;5;241m.\u001b[39mprod(l\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m _model\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(l, nn\u001b[38;5;241m.\u001b[39mLinear))\n\u001b[1;32m     39\u001b[0m _img_syn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m*\u001b[39min_shape)\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Input of network\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m _student_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m     41\u001b[0m     [[l\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m _model\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(l, nn\u001b[38;5;241m.\u001b[39mLinear)] \u001b[38;5;241m+\u001b[39m [l\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m _model\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(l, nn\u001b[38;5;241m.\u001b[39mLinear)]]\n\u001b[1;32m     42\u001b[0m )\u001b[38;5;241m.\u001b[39mrequires_grad_(\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     44\u001b[0m )  \u001b[38;5;66;03m# Imaginary parameters, in MTT sometimes called forward_param. These are the weights!\u001b[39;00m\n\u001b[1;32m     45\u001b[0m starting_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(num_params)  \u001b[38;5;66;03m# Imaginary starting expert param\u001b[39;00m\n\u001b[1;32m     46\u001b[0m target_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(num_params)  \u001b[38;5;66;03m# Imaginary ending expert param\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got list"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import copy\n",
    "from torchviz import make_dot\n",
    "\n",
    "from src.reparam_module import ReparamModule\n",
    "\n",
    "# These are our reference variables that we wish to keep, to compare between models\n",
    "\n",
    "# Input batch\n",
    "# N = 7 # No batch for now, just a single variable\n",
    "\n",
    "in_shape = (2, 3) # Batch, features\n",
    "l1 = (in_shape[1], 4) # Shape of Linear Layer\n",
    "\n",
    "class TestLinear(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # No bias because in MTT, we are using normalization layers\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_features=l1[0], out_features=l1[1], bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=l1[1], out_features=8, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, out_features=5, bias=  ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "# Avoid using these directly, instead use deepcopies\n",
    "_model = TestLinear()\n",
    "num_params = sum(np.prod(l.weight.shape) for l in _model.layers if isinstance(l, nn.Linear))\n",
    "_img_syn = torch.randn(*in_shape).requires_grad_(True)  # Input of network\n",
    "_student_params = torch.cat(\n",
    "    [[l.weight.reshape(-1) for l in _model.layers if isinstance(l, nn.Linear)]]\n",
    ").requires_grad_(\n",
    "    True\n",
    ")  # Imaginary parameters, in MTT sometimes called forward_param. These are the weights!\n",
    "starting_params = torch.randn(num_params)  # Imaginary starting expert param\n",
    "target_params = torch.randn(num_params)  # Imaginary ending expert param\n",
    "y_hat = torch.empty(in_shape[0], dtype=torch.long).random_(4) # Imaginary targets, shape output of final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "split_with_sizes expects split_sizes to sum exactly to 84 (input tensor's size at dimension 0), but got split_sizes=[12, 4, 32, 8, 40, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer_img\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     14\u001b[0m student_net_mtt\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 16\u001b[0m out \u001b[38;5;241m=\u001b[39m student_net_mtt(img_syn, flat_param\u001b[38;5;241m=\u001b[39mstudent_params) \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     17\u001b[0m out\u001b[38;5;241m.\u001b[39mretain_grad() \u001b[38;5;66;03m# For validation\u001b[39;00m\n\u001b[1;32m     18\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()  \u001b[38;5;66;03m# Used to calculate gradients of parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/thesis/mtt_jupyter/src/reparam_module.py:160\u001b[0m, in \u001b[0;36mReparamModule.forward\u001b[0;34m(self, flat_param, buffers, *inputs, **kwinputs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     flat_param \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflat_param\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# This is an extremely important line\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# What it does is replace the parameters with those of flat_param, this\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# means that the autograd step in distill.py actually does something\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_with_param(flat_param, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwinputs)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_with_param_and_buffers(flat_param, \u001b[38;5;28mtuple\u001b[39m(buffers), \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwinputs)\n",
      "File \u001b[0;32m~/Documents/thesis/mtt_jupyter/src/reparam_module.py:145\u001b[0m, in \u001b[0;36mReparamModule._forward_with_param\u001b[0;34m(self, flat_param, *inputs, **kwinputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_with_param\u001b[39m(\u001b[38;5;28mself\u001b[39m, flat_param, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwinputs):\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munflattened_param(flat_param):\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwinputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.12/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/thesis/mtt_jupyter/src/reparam_module.py:120\u001b[0m, in \u001b[0;36mReparamModule.unflattened_param\u001b[0;34m(self, flat_param)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munflattened_param\u001b[39m(\u001b[38;5;28mself\u001b[39m, flat_param):\n\u001b[1;32m    119\u001b[0m     saved_views \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module_from_name(mn), n) \u001b[38;5;28;01mfor\u001b[39;00m mn, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_infos]\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unflatten_param(flat_param)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# Why not just `self._unflatten_param(self.flat_param)`?\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# 1. because of https://github.com/pytorch/pytorch/issues/17583\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# 2. slightly faster since it does not require reconstruct the split+view\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;66;03m#    graph\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/thesis/mtt_jupyter/src/reparam_module.py:111\u001b[0m, in \u001b[0;36mReparamModule._unflatten_param\u001b[0;34m(self, flat_param)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unflatten_param\u001b[39m(\u001b[38;5;28mself\u001b[39m, flat_param):\n\u001b[0;32m--> 111\u001b[0m     ps \u001b[38;5;241m=\u001b[39m (t\u001b[38;5;241m.\u001b[39mview(s) \u001b[38;5;28;01mfor\u001b[39;00m (t, s) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flat_param\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_numels), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_shapes))\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (mn, n), p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_param_infos, ps):\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module_from_name(mn), n, p)  \u001b[38;5;66;03m# This will set as plain attr\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.12/site-packages/torch/_tensor.py:921\u001b[0m, in \u001b[0;36mTensor.split\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_VF\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m, split_size, dim)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_VF\u001b[38;5;241m.\u001b[39msplit_with_sizes(\u001b[38;5;28mself\u001b[39m, split_size, dim)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: split_with_sizes expects split_sizes to sum exactly to 84 (input tensor's size at dimension 0), but got split_sizes=[12, 4, 32, 8, 40, 5]"
     ]
    }
   ],
   "source": [
    "# MTT Ground Truth, we are trying to replicate the input image gradients\n",
    "\n",
    "# Deep copies, so we know not used by manual implementation\n",
    "img_syn = copy.deepcopy(_img_syn)\n",
    "# I don't think it is possible to do a deepcopy as this removes dependencies\n",
    "student_params = _student_params\n",
    "student_params.retain_grad()\n",
    "student_net_mtt = _model\n",
    "student_net_mtt = ReparamModule(student_net_mtt)  # MTT black magic\n",
    "\n",
    "optimizer_img = torch.optim.SGD([img_syn], lr=0.1, momentum=0.5)\n",
    "optimizer_img.zero_grad()\n",
    "\n",
    "student_net_mtt.train()\n",
    "\n",
    "out = student_net_mtt(img_syn, flat_param=student_params) # Forward pass\n",
    "out.retain_grad() # For validation\n",
    "criterion = nn.CrossEntropyLoss()  # Used to calculate gradients of parameters\n",
    "ce_loss = criterion(out, y_hat) # NllLossBackward0\n",
    "ce_loss.retain_grad() # For validation\n",
    "\n",
    "# Computes graph for student_params, but does not populate the .grad attributes!\n",
    "# Returns a tuple with only a single term\n",
    "grad = torch.autograd.grad(ce_loss, student_params, create_graph=True)[0] # CatBackward0\n",
    "grad.retain_grad()\n",
    "\n",
    "# Update student params (instead of using torch.optim.SGD)\n",
    "student_params_new = (student_params - 0.1 * grad) # SubBackward0, MulBackward0, CatBackward0, ViewBackward0,\n",
    "student_params_new.retain_grad() # For validation\n",
    "\n",
    "param_loss = torch.nn.functional.mse_loss(student_params_new, target_params, reduction=\"sum\") # MseLossBackward0\n",
    "param_loss.retain_grad() # For validation\n",
    "param_dist = torch.nn.functional.mse_loss(starting_params, target_params, reduction=\"sum\")\n",
    "\n",
    "# Believe this is their manual way of taking the mean lol. But this isn't actually needed\n",
    "# because they have done num_param / num_param = 1\n",
    "# param_loss /= num_params\n",
    "# param_dist /= num_params\n",
    "\n",
    "# MTT grand loss, with the full computational graph determined by autograd\n",
    "grand_loss = param_loss / param_dist\n",
    "grand_loss.retain_grad() # For validation\n",
    "\n",
    "# Before backwards pass of grand loss, gradient should be zero\n",
    "assert img_syn.grad == None\n",
    "optimizer_img.zero_grad()\n",
    "\n",
    "# Now do backprop, and calculate\n",
    "grand_loss.backward(retain_graph=True) # retain_graph for torchviz\n",
    "\n",
    "print(grand_loss)\n",
    "print(img_syn.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img/mtt_grand_linear.pdf'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# graph = make_dot(loss_grand, show_attrs=True) # Verbose, requires retaining graph\n",
    "graph = make_dot(grand_loss, show_attrs=True)\n",
    "# Img may be cut off, hence save to a file\n",
    "graph.render(\"img/mtt_grand_linear\", view=True, format=\"pdf\")\n",
    "# graph\n",
    "\n",
    "# # graph = make_dot(loss_grand, show_attrs=True) # Verbose, requires retaining graph\n",
    "# graph = make_dot(grad, show_attrs=True)\n",
    "# # Img may be cut off, hence save to a file\n",
    "# graph.render(\"img/grad\", view=True, format=\"pdf\")\n",
    "# # graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3276, 0.1205, 0.4679, 0.0840],\n",
      "        [0.2291, 0.1715, 0.5255, 0.0739]], grad_fn=<DivBackward0>)\n",
      "tensor([0, 1])\n",
      "tensor([[ 0.3276,  0.1205, -0.5321,  0.0840],\n",
      "        [ 0.2291,  0.1715,  0.5255, -0.9261]], grad_fn=<IndexPutBackward0>)\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# let us calculate the forward computational graph manually\n",
    "\n",
    "# print(ce_loss)\n",
    "\n",
    "# Calculate CELoss forward\n",
    "flat_reshaped = torch.reshape(student_params, (4,3))\n",
    "# y_truth_one_hot = torch.zeros_like(out, dtype=int)  # Same shape as model output\n",
    "y_truth_one_hot = torch.zeros_like(img_syn @ flat_reshaped.T, dtype=int)  # This is the forward pass of normal DNN\n",
    "y_truth_one_hot[torch.arange(out.shape[0]), y_hat] = (\n",
    "    1  # Assign index of label as 1, others are 0\n",
    ")\n",
    "y_max = torch.max(out, axis=1, keepdims=True)[0]\n",
    "y_out_exp = torch.exp(out - y_max)\n",
    "y_out_probs = y_out_exp / torch.sum(y_out_exp, axis=1, keepdims=True) # Cached for backwards\n",
    "loss_val = -y_truth_one_hot * torch.log(y_out_probs)\n",
    "loss_val = loss_val.sum(axis=1).mean()\n",
    "assert torch.allclose(loss_val, ce_loss)\n",
    "# print(y_out_probs.shape)\n",
    "# Here we are forward passing the backprop of CELoss (yes, this will confuse you)\n",
    "dout_val = y_out_probs\n",
    "print(dout_val)\n",
    "print(torch.arange(out.shape[0]))\n",
    "dout_val[torch.arange(out.shape[0]), y_hat] -= 1\n",
    "print(dout_val)\n",
    "dout_val /= out.shape[0]  # Hand calculated dout to validate\n",
    "\n",
    "print(dout_val.shape)\n",
    "\n",
    "# # Calculate MmBackward0 forward (the 'hidden' layer)\n",
    "MmForward = dout_val.T @ img_syn\n",
    "MmForward = MmForward.view(-1)\n",
    "assert torch.allclose(MmForward, grad)\n",
    "_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[ 0.0030,  0.0004,  0.0008],\n",
      "        [-0.0061, -0.0013, -0.0025]], grad_fn=<MmBackward0>)\n",
      "tensor([[ 0.0016,  0.0010,  0.0007],\n",
      "        [-0.0064, -0.0011, -0.0023]])\n"
     ]
    }
   ],
   "source": [
    "# Now let us calculate img_syn.grad manually\n",
    "\n",
    "# dparam_loss (MSELoss wrt student_params_new)\n",
    "dMSE = 2 * (student_params_new - target_params) / param_dist\n",
    "# print(student_params.grad)\n",
    "# print(dparam_loss)\n",
    "# print(student_params.grad - dparam_loss)\n",
    "assert(torch.allclose(student_params_new.grad, dMSE))\n",
    "\n",
    "# dstudent_params_grad\n",
    "# Take derivative of student_param_new wrt grad * incoming gradient\n",
    "# This is the gradient that leaves the first MulBackward0 at bottom of graph\n",
    "dstudent_params_grad = -0.1 * dMSE\n",
    "# print(grad.grad)\n",
    "# print(d_student_params)\n",
    "# print(grad.grad- d_student_params)\n",
    "assert(torch.allclose(grad.grad, dstudent_params_grad))\n",
    "\n",
    "# dstudent_params_student_params (incoming grad. wrt student_params)\n",
    "# Take derivative of student_param wrt student_param * incoming gradient\n",
    "# TODO: This is dparam_loss plus whatever the other incoming gradient is (accumulate)\n",
    "# This is the gradient that enters the CatBackward0 at the top of the graph\n",
    "# dstudent_params_student_params = dparam_loss\n",
    "# assert(torch.allclose(student_params.grad, dstudent_params_student_params))\n",
    "\n",
    "# dMmBackward0 (hidden layer)\n",
    "\n",
    "# Calculate backprop through the CELoss layer\n",
    "# back = dstudent_params_grad / out.shape[0]\n",
    "# back = torch.reshape(back, (3,4))\n",
    "# # back[torch.arange(out.shape[0]), y_hat] -= 1\n",
    "# print(back.shape)\n",
    "# TODO: Figure out to backprop through the backprop of CELoss\n",
    "dtmp = img_syn @ torch.reshape(dstudent_params_grad, (4,3)).T # Should be same shape as dout_val (2,4)\n",
    "dtmp /= out.shape[0]\n",
    "\n",
    "print(dtmp.shape)\n",
    "# dtmp = dtmp @ flat_reshaped\n",
    "\n",
    "\n",
    "# Incoming gradient is dstudent_params_grad or grad.grad\n",
    "# d_hidden = dout_val @ torch.reshape(grad.grad, (4,3))\n",
    "d_hidden = dout_val @ torch.reshape(dstudent_params_grad, (4,3))\n",
    "print(d_hidden)\n",
    "print(img_syn.grad)\n",
    "# print(img_syn.grad - dtmp - d_hidden) # Trying to get this to zero\n",
    "\n",
    "# dgrad (incoming grad. wrt grad)\n",
    "# TODO: This must be examined in detail, check why it is 1\n",
    "# Think it is because we backprop CE itself, not its gradient\n",
    "# print(ce_loss.grad)\n",
    "# dgrad = torch.tensor([1.0])\n",
    "# # print(ce_loss.grad - dgrad)\n",
    "# assert(torch.allclose(ce_loss.grad, dgrad))\n",
    "\n",
    "# dstudent_params wrt grad\n",
    "# First we have to calculate this weird 'hidden' layer\n",
    "\n",
    "# dhidden = torch.ones_like(grad) * -0.1\n",
    "# print(dhidden)\n",
    "\n",
    "# dCELoss\n",
    "# out is the last MMBackward0 before the AccumulateGrad for x\n",
    "\n",
    "# print(out.shape)\n",
    "# print(out - d_student_params.reshape([4,3]))\n",
    "# out_test = out - img_syn @ torch.reshape(d_student_params, (3,4))\n",
    "\n",
    "# out_exp = torch.exp(out - torch.max(out, axis=1, keepdims=True)[0])\n",
    "# y_out_probs = out_exp / torch.sum(out_exp, axis=1, keepdims=True) # Forwards caches this\n",
    "# dce_loss = y_out_probs\n",
    "# dce_loss[torch.arange(out.shape[0]), y_hat] -= 1\n",
    "# dce_loss /= out.shape[0]\n",
    "\n",
    "# out_npy = out.detach().numpy()\n",
    "# y_hat = y_hat.numpy()\n",
    "# out_exp = np.exp(out_npy - np.max(out_npy, axis=1, keepdims=True)[0])\n",
    "# y_out_probs = out_exp / np.sum(out_exp, axis=1, keepdims=True) # Forwards caches this\n",
    "# dce_loss = y_out_probs\n",
    "# dce_loss[np.arange(out_npy.shape[0]), y_hat] -= 1.0\n",
    "# dce_loss /= out_npy.shape[0]\n",
    "# print(dce_loss - out.grad.detach().numpy())\n",
    "\n",
    "# print(dce_loss - out.grad)\n",
    "# print(img_syn)\n",
    "# print(dce_loss / out.grad)\n",
    "# assert(torch.allclose(out.grad, dce_loss)) # The difference here is quite large, maybe torch calculates differently?\n",
    "\n",
    "# dout (can't calculate it directly yet)\n",
    "\n",
    "# print(out.grad.shape)\n",
    "# print(torch.reshape(student_params, [4,3]).shape)\n",
    "\n",
    "# dhidden_truth = out.grad - img_syn.grad\n",
    "# print(dhidden_truth)\n",
    "\n",
    "\n",
    "\n",
    "_ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(grad)\n",
    "\n",
    "# current = grad\n",
    "\n",
    "# while current.grad_fn is not None:\n",
    "#     print(current.grad_fn)\n",
    "#     current = current.grad_fn.next_functions[0][0]  # Move to the next function in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
